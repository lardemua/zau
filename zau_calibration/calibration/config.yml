#
#           █████╗ ████████╗ ██████╗ ███╗   ███╗
#          ██╔══██╗╚══██╔══╝██╔═══██╗████╗ ████║
#          ███████║   ██║   ██║   ██║██╔████╔██║
#          ██╔══██║   ██║   ██║   ██║██║╚██╔╝██║
#   __     ██║  ██║   ██║   ╚██████╔╝██║ ╚═╝ ██║    _
#  / _|    ╚═╝  ╚═╝   ╚═╝    ╚═════╝ ╚═╝     ╚═╝   | |
#  | |_ _ __ __ _ _ __ ___   _____      _____  _ __| | __
#  |  _| '__/ _` | '_ ` _ \ / _ \ \ /\ / / _ \| '__| |/ /
#  | | | | | (_| | | | | | |  __/\ V  V / (_) | |  |   <
#  |_| |_|  \__,_|_| |_| |_|\___| \_/\_/ \___/|_|  |_|\_\
#  https://github.com/lardemua/atom
# Auto-generated file on 22/04/2024 22:06:02

# This yaml file describes your calibration!


# Start by defining your robotic system.
# This is the URDF file (or xacro) that describes your robot.
# Every time a path to a file is requested you can use
#
#   - Absolute Path
#       Example 1: /home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#       Example 2: file://home/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#   - Path Expansion
#       Example 1: ${HOME}/user/${YOUR_VARIABLE}/your_package/urdf/description.urdf.xacro
#       Example 2: ~/user/ros_workspace/your_package/urdf/description.urdf.xacro
#
#       NOTE: It is up to you to guarantee the environment variable exists.
#
#   - ROS Package Reference
#       Example: package://your_package/urdf/description.urdf.xacro
#
description_file: "package://zau_description/urdf/zau.urdf.xacro"

# The calibration framework requires a bagfile to extract the necessary data for the calibration.
# bag_file: "$ROS_BAGS/zau/inesc_day1_1_cropped_renamed_without_splits.bag"
# bag_file: "$ROS_BAGS/zau/inesc_day2_1_renamed_without_vo.bag"
bag_file: "$ROS_BAGS/zau/inesc_day2_2_processed.bag"

# You must define a frame of reference for the optimization process.
# It must exist in the transformation chains of all the sensors which are being calibrated.
world_link: "world"

# ATOM will calibrate the extrinsic parameters of your sensors.
# In this section you should discriminate the sensors that will be part of the calibrations.
sensors:
  # Each key will define a sensor and its name, which will be use throughout the calibration.
  # Each sensor definition must have the following properties:
  #       link:
  #           The frame of the sensor's data (i.e. the header.frame_id).
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #       topic_name:
  #           Name of the ROS topic that contains the data produced by this sensor.
  #           If you are calibrating an camera, you should use the raw image produced by the
  #           sensors. Additionally, it the topic is an image it will automatically use the
  #           respective `camera_info` topic.
  #       modality:
  #           Set this to identify the sensor modality. If this flag is not set, the sensor will be
  #           identified by the message type.
  #           Current options: lidar3d, rgb, depth, lidar2d
  #       throttle:
  #           Set throttle: desired_frame_rate. If you don't use throttle, do not enter a value, i.e. "throttle: "
  #
  # If you are using an image compressed topic such as:
  #   /world_camera/rgb/image_raw/compressed
  # you should not add the "compressed" part, use only:
  #   /world_camera/rgb/image_raw
  #

  rgbd_hand_color:
    link: "rgbd_hand_color_optical_frame"
    parent_link: "rgbd_hand_link"
    child_link: "rgbd_hand_color_frame"
    topic_name: "/rgbd_hand/color/image_raw"
    modality: "rgb"
    throttle: 10

  rgbd_hand_depth:
    link: "rgbd_hand_depth_optical_frame"
    parent_link: "rgbd_hand_link"
    child_link: "rgbd_hand_depth_frame"
    topic_name: "/rgbd_hand/depth/image_raw"
    modality: "depth"
    throttle: 10

  # You can have more than one sensor:
  rgb_body_left:
    link: "rgb_body_left_optical_frame"
    parent_link: "base_link_mb"
    child_link: "rgb_body_left_link"
    topic_name: "/rgb_body_left/image_raw"
    modality: "rgb"
    throttle: 10

  rgb_body_right:
    link: "rgb_body_right_optical_frame"
    parent_link: "base_link_mb"
    child_link: "rgb_body_right_link"
    topic_name: "/rgb_body_right/image_raw"
    modality: "rgb"
    throttle: 


  # TO-DO: RECORD BAG WITH LIDAR PointCloud
  lidar_body:
    link: "lidar_body"
    parent_link: "base_link_mb"
    child_link: "lidar_body_base_link"
    topic_name: "/lidar_body/points"
    modality: "lidar3d"
    throttle:


  # TO-DO: ADD FE FROM T265
  # vo_body_fisheye1:
  #   link: "vo_body_fisheye1_optical_frame"
  #   parent_link: "" # ?
  #   child_link: "vo_body_link"
  #   topic_name: "/vo_body/fisheye1/image_raw"
  #   modality: "rgb"
  #   throttle:
  
  # # TO-DO: ADD FE FROM T265
  # vo_body_fisheye2:
  #   link: "vo_body_fisheye2_optical_frame"
  #   parent_link: "" # ?
  #   child_link: "vo_body_link"
  #   topic_name: "/vo_body/fisheye2/image_raw"
  #   modality: "rgb"
  #   throttle:

# ATOM will calibrate the extrinsic parameters of your links.
# In this section you should discriminate the additional transformations that will be part of the calibrations.
additional_tfs:
  # Each key will define a transformations and its name, which will be use throughout the calibration.
  # Each additional transformations definition must have the following properties:
  #
  #       parent_link:
  #           The parent link of the transformation (i.e. link) to be calibrated.
  #
  #       child_link:
  #           This is the transformation (i.e. link) that we be optimized.
  #
  # EXAMPLE:
  base_link_mb_to_base_link:
   parent_link: "base_link_mb"
   child_link: "base_link"

# ATOM can also calibrate several parameters of your joints.
# In this section you should discriminate the joints that will be part of the calibrations.
# For each joint you must specify which parameters to optimize.
# The joint is identified by its name, consistent with the URDF description.
joints:
  # Each key will define a joint and its name, which will be use throughout the calibration.
  # Each joint definition must have the following properties:
  #
  #       params_to_calibrate:
  #           This is the list of parameters that will be optimized, from the urdf definition (http://wiki.ros.org/urdf/XML/joint):
  #           ['origin_x', 'origin_y', 'origin_z', 'origin_roll', 'origin_pitch', 'origin_yaw']
  #
  # EXAMPLE:
  #head_pan_joint:
  #  params_to_calibrate: ['origin_yaw']

# The calibration requires at least one detectable pattern.
# This section describes the properties of the calibration pattern(s) used in the calibration.
calibration_patterns:

  pattern_1:
    # The frame id (or link) of the pattern.
    # This link/transformation will be optimized.
    link: "pattern_link"

    # The parent frame id (or link) of the pattern.
    # For example, in hand-eye calibration the parent link
    # of the pattern can be the end-effector or the base of the arm
    parent_link: "world" 

    # Defines if the pattern link is the same in all collections (i.e. fixed=true),
    # or each collection will have its own estimate of the link transformation.
    # Note: if you plan to have the pattern fixed, while the moving the rigidly attached sensors,
    # this is equivalent to having the sensors fixed and the pattern moving, so you should use fixed=false.
    fixed: true

    # The type of pattern used for the calibration.
    # Supported pattern are:
    # - chessboard
    # - charuco
    pattern_type: "charuco"

    # If the pattern type is "charuco" you need to define
    # the aruco dictionary used by the pattern.
    # See https://docs.opencv.org/trunk/dc/df7/dictionary_8hpp.html
    dictionary: "DICT_5X5_100"

    # Mesh file (collada.dae or stl) for showing pattern on rviz. URI or regular path.
    # See: atom_worlds/patterns/models for options.
    mesh_file: "package://atom_worlds/pattern/models/charuco_800x600_5x5_100/charuco_800x600_5x5_100.dae"

    # The border width from the edge corner to the pattern physical edge.
    # Used for 3D sensors and lidars.
    # It can be a scalar (same border in x and y directions), or it can be {'x': ..., 'y': ,,,}
    border_size: { 'x': 0.04, 'y': 0.03 }

    # The number of corners the pattern has in the X and Y dimensions.
    # Note: The charuco detector uses the number of squares per dimension in its detector.
    # Internally we add a +1 to Y and X dimensions to account for that.
    # Therefore, the number of corners should be used even for the charuco pattern.
    dimension: { "x": 11, "y": 8 }

    # The length of the square edge.
    size: 0.06

    # The length of the charuco inner marker.
    inner_size: 0.045


# Miscellaneous configuration

# If your calibration problem is not fully constrained you should anchored one of the sensors.
# This makes it immovable during the optimization.
# Leave empty if no sensor is to be anchored.
anchored_sensor:

# Max time delta (in milliseconds) between sensor data messages when creating a collection.
max_duration_between_msgs: 1000

# This parameter is automatically filled by ATOM, please only change if you know what you are doing
package_name: "zau_calibration"

# Automatically filled. Do not touch unless you know what you are doing.
version: 3.0